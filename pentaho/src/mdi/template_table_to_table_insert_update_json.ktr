<transformation>
  <info>
    <name>template_table_to_table_insert_update_json</name>
    <description/>
    <extended_description/>
    <trans_version/>
    <trans_type>Normal</trans_type>
    <trans_status>0</trans_status>
    <directory>/mdi</directory>
    <parameters>
      <parameter>
        <name>database_hostname</name>
        <default_value/>
        <description/>
      </parameter>
      <parameter>
        <name>database_password</name>
        <default_value/>
        <description/>
      </parameter>
      <parameter>
        <name>database_port</name>
        <default_value/>
        <description/>
      </parameter>
      <parameter>
        <name>database_schema</name>
        <default_value/>
        <description/>
      </parameter>
      <parameter>
        <name>database_username</name>
        <default_value/>
        <description/>
      </parameter>
      <parameter>
        <name>environment</name>
        <default_value/>
        <description/>
      </parameter>
      <parameter>
        <name>etl_batch_id</name>
        <default_value/>
        <description/>
      </parameter>
      <parameter>
        <name>input_data</name>
        <default_value/>
        <description>The JSON string passed from a step function.</description>
      </parameter>
    </parameters>
    <log>
      <trans-log-table>
        <connection>Config DB Connection</connection>
        <schema>log</schema>
        <table>transformation_transformation</table>
        <size_limit_lines/>
        <interval>5</interval>
        <timeout_days>90</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STATUS</id>
          <enabled>Y</enabled>
          <name>STATUS</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
          <subject/>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
          <subject/>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
          <subject/>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
          <subject/>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
          <subject/>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
          <subject/>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>STARTDATE</id>
          <enabled>Y</enabled>
          <name>STARTDATE</name>
        </field>
        <field>
          <id>ENDDATE</id>
          <enabled>Y</enabled>
          <name>ENDDATE</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>DEPDATE</id>
          <enabled>Y</enabled>
          <name>DEPDATE</name>
        </field>
        <field>
          <id>REPLAYDATE</id>
          <enabled>Y</enabled>
          <name>REPLAYDATE</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>Y</enabled>
          <name>LOG_FIELD</name>
        </field>
        <field>
          <id>EXECUTING_SERVER</id>
          <enabled>Y</enabled>
          <name>EXECUTING_SERVER</name>
        </field>
        <field>
          <id>EXECUTING_USER</id>
          <enabled>Y</enabled>
          <name>EXECUTING_USER</name>
        </field>
        <field>
          <id>CLIENT</id>
          <enabled>Y</enabled>
          <name>CLIENT</name>
        </field>
      </trans-log-table>
      <perf-log-table>
        <connection>Config DB Connection</connection>
        <schema>log</schema>
        <table>transformation_performance</table>
        <interval>5</interval>
        <timeout_days>90</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>SEQ_NR</id>
          <enabled>Y</enabled>
          <name>SEQ_NR</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>INPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>INPUT_BUFFER_ROWS</name>
        </field>
        <field>
          <id>OUTPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>OUTPUT_BUFFER_ROWS</name>
        </field>
      </perf-log-table>
      <channel-log-table>
        <connection>Config DB Connection</connection>
        <schema>log</schema>
        <table>transformation_channel</table>
        <timeout_days>90</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>LOGGING_OBJECT_TYPE</id>
          <enabled>Y</enabled>
          <name>LOGGING_OBJECT_TYPE</name>
        </field>
        <field>
          <id>OBJECT_NAME</id>
          <enabled>Y</enabled>
          <name>OBJECT_NAME</name>
        </field>
        <field>
          <id>OBJECT_COPY</id>
          <enabled>Y</enabled>
          <name>OBJECT_COPY</name>
        </field>
        <field>
          <id>REPOSITORY_DIRECTORY</id>
          <enabled>Y</enabled>
          <name>REPOSITORY_DIRECTORY</name>
        </field>
        <field>
          <id>FILENAME</id>
          <enabled>Y</enabled>
          <name>FILENAME</name>
        </field>
        <field>
          <id>OBJECT_ID</id>
          <enabled>Y</enabled>
          <name>OBJECT_ID</name>
        </field>
        <field>
          <id>OBJECT_REVISION</id>
          <enabled>Y</enabled>
          <name>OBJECT_REVISION</name>
        </field>
        <field>
          <id>PARENT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>PARENT_CHANNEL_ID</name>
        </field>
        <field>
          <id>ROOT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>ROOT_CHANNEL_ID</name>
        </field>
      </channel-log-table>
      <step-log-table>
        <connection>Config DB Connection</connection>
        <schema>log</schema>
        <table>transformation_step</table>
        <timeout_days>90</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>Y</enabled>
          <name>LOG_FIELD</name>
        </field>
      </step-log-table>
      <metrics-log-table>
        <connection>Config DB Connection</connection>
        <schema>log</schema>
        <table>transformation_metrics</table>
        <timeout_days>90</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>METRICS_DATE</id>
          <enabled>Y</enabled>
          <name>METRICS_DATE</name>
        </field>
        <field>
          <id>METRICS_CODE</id>
          <enabled>Y</enabled>
          <name>METRICS_CODE</name>
        </field>
        <field>
          <id>METRICS_DESCRIPTION</id>
          <enabled>Y</enabled>
          <name>METRICS_DESCRIPTION</name>
        </field>
        <field>
          <id>METRICS_SUBJECT</id>
          <enabled>Y</enabled>
          <name>METRICS_SUBJECT</name>
        </field>
        <field>
          <id>METRICS_TYPE</id>
          <enabled>Y</enabled>
          <name>METRICS_TYPE</name>
        </field>
        <field>
          <id>METRICS_VALUE</id>
          <enabled>Y</enabled>
          <name>METRICS_VALUE</name>
        </field>
      </metrics-log-table>
    </log>
    <maxdate>
      <connection/>
      <table/>
      <field/>
      <offset>0.0</offset>
      <maxdiff>0.0</maxdiff>
    </maxdate>
    <size_rowset>10000</size_rowset>
    <sleep_time_empty>50</sleep_time_empty>
    <sleep_time_full>50</sleep_time_full>
    <unique_connections>N</unique_connections>
    <feedback_shown>Y</feedback_shown>
    <feedback_size>50000</feedback_size>
    <using_thread_priorities>Y</using_thread_priorities>
    <shared_objects_file/>
    <capture_step_performance>N</capture_step_performance>
    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
    <dependencies>
    </dependencies>
    <partitionschemas>
    </partitionschemas>
    <slaveservers>
    </slaveservers>
    <clusterschemas>
    </clusterschemas>
    <created_user>-</created_user>
    <created_date>2020/09/15 15:00:08.871</created_date>
    <modified_user>-</modified_user>
    <modified_date>2021/06/08 16:42:55.751</modified_date>
    <key_for_session_key>H4sIAAAAAAAAAAMAAAAAAAAAAAA=</key_for_session_key>
    <is_key_private>N</is_key_private>
  </info>
  <notepads>
    <notepad>
      <note>Load Data from Database Table






</note>
      <xloc>128</xloc>
      <yloc>80</yloc>
      <width>652</width>
      <heigth>232</heigth>
      <fontname>Segoe UI</fontname>
      <fontsize>12</fontsize>
      <fontbold>Y</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>192</backgroundcolorred>
      <backgroundcolorgreen>192</backgroundcolorgreen>
      <backgroundcolorblue>192</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Add ETL Batch ID to stream







</note>
      <xloc>128</xloc>
      <yloc>352</yloc>
      <width>652</width>
      <heigth>260</heigth>
      <fontname>Segoe UI</fontname>
      <fontsize>12</fontsize>
      <fontbold>Y</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>192</backgroundcolorred>
      <backgroundcolorgreen>192</backgroundcolorgreen>
      <backgroundcolorblue>192</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Save stream to table






</note>
      <xloc>128</xloc>
      <yloc>976</yloc>
      <width>652</width>
      <heigth>232</heigth>
      <fontname>Segoe UI</fontname>
      <fontsize>12</fontsize>
      <fontbold>Y</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>192</backgroundcolorred>
      <backgroundcolorgreen>192</backgroundcolorgreen>
      <backgroundcolorblue>192</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Specify logging fields, log them, and abort transformation as error                                                                                                                               






</note>
      <xloc>336</xloc>
      <yloc>1264</yloc>
      <width>1024</width>
      <heigth>179</heigth>
      <fontname>Segoe UI</fontname>
      <fontsize>12</fontsize>
      <fontbold>Y</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>192</backgroundcolorred>
      <backgroundcolorgreen>192</backgroundcolorgreen>
      <backgroundcolorblue>192</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Add Data Source DWID to stream







</note>
      <xloc>128</xloc>
      <yloc>656</yloc>
      <width>700</width>
      <heigth>260</heigth>
      <fontname>Segoe UI</fontname>
      <fontsize>12</fontsize>
      <fontbold>Y</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>192</backgroundcolorred>
      <backgroundcolorgreen>192</backgroundcolorgreen>
      <backgroundcolorblue>192</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>JSON output														



















































</note>
      <xloc>944</xloc>
      <yloc>80</yloc>
      <width>1090</width>
      <heigth>1123</heigth>
      <fontname>Segoe UI</fontname>
      <fontsize>12</fontsize>
      <fontbold>Y</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>128</backgroundcolorred>
      <backgroundcolorgreen>255</backgroundcolorgreen>
      <backgroundcolorblue>255</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <connection>
    <name>Config DB Connection</name>
    <server>${database_hostname}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>config</database>
    <port>${database_port}</port>
    <username>${database_username}</username>
    <password>${database_password}</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute>
        <code>EXTRA_OPTION_POSTGRESQL.SEQUENCE_FOR_BATCH_ID</code>
        <attribute>pentaho_logging_sequence</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${database_port}</attribute>
      </attribute>
      <attribute>
        <code>PREFERRED_SCHEMA_NAME</code>
        <attribute>ingress</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <connection>
    <name>Dummy DB Connection</name>
    <server>use when a default connection is needed</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>.</database>
    <port>5432</port>
    <username>.</username>
    <password>Encrypted 2be98afc86aa7f2e4cb79ce10bef2cf94</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>5432</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <order>
    <hop>
      <from>[template_table_to_table_insert_update_json] add a blank field for etl_batch_id to valid stream</from>
      <to>[template_table_to_table_insert_update_json] Set etl_batch_id field value to parameter etl_batch_id</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json]  Specify logging fields (non-sensitive)</from>
      <to>[template_table_to_table_insert_update_json]  Abort Table Output</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] add a blank field for data_source_dwid to valid stream</from>
      <to>[template_table_to_table_insert_update_json] Set data_source_dwid field value to parameter data_source_dwid</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] Set etl_batch_id field value to parameter etl_batch_id</from>
      <to>[template_table_to_table_insert_update_json] add a blank field for data_source_dwid to valid stream</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] Table input</from>
      <to>[template_table_to_table_insert_update_json] add a blank field for etl_batch_id to valid stream</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] Set data_source_dwid field value to parameter data_source_dwid</from>
      <to>[template_table_to_table_insert_update_json] Insert / update</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] Insert / update</from>
      <to>[template_table_to_table_insert_update_json]  Specify logging fields (non-sensitive)</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] Filter rows</from>
      <to>[template_table_to_table_insert_update_json] Full load - set key_field_name and key_field_values to NULL</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] Table input</from>
      <to>[template_table_to_table_insert_update_json] Select key field rows</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] Add blank field for key_field_name</from>
      <to>[template_table_to_table_insert_update_json] Set key_field_name</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] Full load - set key_field_name and key_field_values to NULL</from>
      <to>[template_table_to_table_insert_update_json] Full load - add hardcoded constants</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] Count and concatenate key field rows</from>
      <to>[template_table_to_table_insert_update_json] Filter rows</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_json] Add blank fields for environment, etl_batch_id, and token_id</from>
      <to>[template_table_to_table_insert_update_json] Set environment</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] Build output JSON and S3 file output path</from>
      <to>[template_table_to_table_insert_update_json] Block S3 step until insert flow finishes</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] Set environment</from>
      <to>[template_table_to_table_insert_update_json] Set etl_batch_id</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] Set etl_batch_id</from>
      <to>[template_table_to_table_insert_update_json] Set token_id</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] Set token_id</from>
      <to>[template_table_to_table_insert_update_json] Build output JSON and S3 file output path</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] Partial load - add hardcoded constant</from>
      <to>[template_table_to_table_insert_json] Add blank fields for environment, etl_batch_id, and token_id</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] Full load - add hardcoded constants</from>
      <to>[template_table_to_table_insert_json] Add blank fields for environment, etl_batch_id, and token_id</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] Block S3 step until insert flow finishes</from>
      <to>[template_table_to_table_insert_update_json] S3 file output</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] Select key field rows</from>
      <to>[template_table_to_table_insert_update_json] Add blank field for key_field_name</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] Set key_field_name</from>
      <to>[template_table_to_table_insert_update_json] Conditionally add quotes to key_field_value_rows</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] Conditionally add quotes to key_field_value_rows</from>
      <to>[template_table_to_table_insert_update_json] Count and concatenate key field rows</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>[template_table_to_table_insert_update_json] Filter rows</from>
      <to>[template_table_to_table_insert_update_json] Partial load - add hardcoded constant</to>
      <enabled>Y</enabled>
    </hop>
  </order>
  <step>
    <name>[template_table_to_table_insert_json] Add blank fields for environment, etl_batch_id, and token_id</name>
    <type>Constant</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <fields>
      <field>
        <name>etl_batch_id</name>
        <type>String</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <nullif/>
        <length>-1</length>
        <precision>-1</precision>
        <set_empty_string>N</set_empty_string>
      </field>
      <field>
        <name>environment</name>
        <type>String</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <nullif/>
        <length>-1</length>
        <precision>-1</precision>
        <set_empty_string>N</set_empty_string>
      </field>
      <field>
        <name>token_id</name>
        <type>String</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <nullif/>
        <length>-1</length>
        <precision>-1</precision>
        <set_empty_string>N</set_empty_string>
      </field>
    </fields>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>1488</xloc>
      <yloc>672</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json]  Abort Table Output</name>
    <type>Abort</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <row_threshold>0</row_threshold>
    <message>could not save data to table</message>
    <always_log_rows>Y</always_log_rows>
    <abort_option>ABORT_WITH_ERROR</abort_option>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>1104</xloc>
      <yloc>1360</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json]  Specify logging fields (non-sensitive)</name>
    <type>SelectValues</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <fields>
      <select_unspecified>N</select_unspecified>
    </fields>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>640</xloc>
      <yloc>1360</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] Add blank field for key_field_name</name>
    <type>Constant</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <fields>
      <field>
        <name>key_field_name</name>
        <type>String</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <nullif/>
        <length>-1</length>
        <precision>-1</precision>
        <set_empty_string>N</set_empty_string>
      </field>
    </fields>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>1488</xloc>
      <yloc>192</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] Block S3 step until insert flow finishes</name>
    <type>BlockUntilStepsFinish</type>
    <description/>
    <distribute>N</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <steps>
      <step>
        <name>[template_table_to_table_insert_update_json] Table input</name>
        <CopyNr>0</CopyNr>
      </step>
      <step>
        <name>[template_table_to_table_insert_update_json] add a blank field for etl_batch_id to valid stream</name>
        <CopyNr>0</CopyNr>
      </step>
      <step>
        <name>[template_table_to_table_insert_update_json] Set etl_batch_id field value to parameter etl_batch_id</name>
        <CopyNr>0</CopyNr>
      </step>
      <step>
        <name>[template_table_to_table_insert_update_json] add a blank field for data_source_dwid to valid stream</name>
        <CopyNr>0</CopyNr>
      </step>
      <step>
        <name>[template_table_to_table_insert_update_json] Set data_source_dwid field value to parameter data_source_dwid</name>
        <CopyNr>0</CopyNr>
      </step>
      <step>
        <name>[template_table_to_table_insert_update_json] Insert / update</name>
        <CopyNr>0</CopyNr>
      </step>
    </steps>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>1488</xloc>
      <yloc>1072</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] Build output JSON and S3 file output path</name>
    <type>ScriptValueMod</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <compatible>N</compatible>
    <optimizationLevel>9</optimizationLevel>
    <jsScripts>
      <jsScript>
        <jsScript_type>0</jsScript_type>
        <jsScript_name>Script 1</jsScript_name>
        <jsScript_script>
// Build output JSON
var outer_json = {};
var inner_json = {};
inner_json.full_load_flag = full_load_flag;
inner_json.key_field_name = key_field_name;
inner_json.key_field_values = key_field_values;
outer_json.token_id = token_id;
outer_json.output = inner_json

var mdi_output_json = JSON.stringify(outer_json);


// Build S3 file output path
var bucket_prefix = environment;
var bucket_postfix = "-data-warehouse-ingress";
var file_string1 = "s3://";
var file_string2 = "/step-function-response/pending/success/";
var etl_batch_id = etl_batch_id;
var bucket = bucket_prefix.concat(bucket_postfix);
var s3_output_filepath = file_string1.concat(bucket, file_string2, etl_batch_id);</jsScript_script>
      </jsScript>
    </jsScripts>
    <fields>
      <field>
        <name>mdi_output_json</name>
        <rename>mdi_output_json</rename>
        <type>String</type>
        <length>-1</length>
        <precision>-1</precision>
        <replace>N</replace>
      </field>
      <field>
        <name>s3_output_filepath</name>
        <rename>s3_output_filepath</rename>
        <type>String</type>
        <length>-1</length>
        <precision>-1</precision>
        <replace>N</replace>
      </field>
    </fields>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>1488</xloc>
      <yloc>992</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] Conditionally add quotes to key_field_value_rows</name>
    <type>ScriptValueMod</type>
    <description/>
    <distribute>N</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <compatible>N</compatible>
    <optimizationLevel>9</optimizationLevel>
    <jsScripts>
      <jsScript>
        <jsScript_type>0</jsScript_type>
        <jsScript_name>Script 1</jsScript_name>
        <jsScript_script>
// Conditionally process key_field_value_rows if key_field_name value does not contain one of the following: pid, dwid
if (/pid|dwid/.test(key_field_name) === true) {
	processed_key_field_value_rows = key_field_value_rows
} else if (/data_source_integration_id|code/.test(key_field_name) === true) {
	processed_key_field_value_rows = ("'" + key_field_value_rows + "'")
} else {
	throw 'key_field_name contains an unexpected value!'
};</jsScript_script>
      </jsScript>
    </jsScripts>
    <fields>
      <field>
        <name>key_field_name</name>
        <rename>key_field_name</rename>
        <type>String</type>
        <length>-1</length>
        <precision>-1</precision>
        <replace>N</replace>
      </field>
      <field>
        <name>processed_key_field_value_rows</name>
        <rename>processed_key_field_value_rows</rename>
        <type>String</type>
        <length>-1</length>
        <precision>-1</precision>
        <replace>N</replace>
      </field>
    </fields>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>1488</xloc>
      <yloc>336</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] Count and concatenate key field rows</name>
    <type>GroupBy</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <all_rows>N</all_rows>
    <ignore_aggregate>N</ignore_aggregate>
    <field_ignore/>
    <directory>%%java.io.tmpdir%%</directory>
    <prefix>grp</prefix>
    <add_linenr>N</add_linenr>
    <linenr_fieldname/>
    <give_back_row>Y</give_back_row>
    <group>
      <field>
        <name>key_field_name</name>
      </field>
    </group>
    <fields>
      <field>
        <aggregate>row_count</aggregate>
        <subject/>
        <type>COUNT_ANY</type>
        <valuefield/>
      </field>
      <field>
        <aggregate>key_field_values</aggregate>
        <subject>processed_key_field_value_rows</subject>
        <type>CONCAT_STRING</type>
        <valuefield>,</valuefield>
      </field>
    </fields>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>1488</xloc>
      <yloc>416</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] Filter rows</name>
    <type>FilterRows</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <send_true_to>[template_table_to_table_insert_update_json] Full load - set key_field_name and key_field_values to NULL</send_true_to>
    <send_false_to>[template_table_to_table_insert_update_json] Partial load - add hardcoded constant</send_false_to>
    <compare>
      <condition>
        <negated>N</negated>
        <leftvalue>row_count</leftvalue>
        <function>&gt;</function>
        <rightvalue/>
        <value>
          <name>constant</name>
          <type>Integer</type>
          <text>1000</text>
          <length>-1</length>
          <precision>0</precision>
          <isnull>N</isnull>
          <mask>####0;-####0</mask>
        </value>
      </condition>
    </compare>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>1488</xloc>
      <yloc>496</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] Full load - add hardcoded constants</name>
    <type>Constant</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <fields>
      <field>
        <name>full_load_flag</name>
        <type>Boolean</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <nullif>TRUE</nullif>
        <length>-1</length>
        <precision>-1</precision>
        <set_empty_string>N</set_empty_string>
      </field>
    </fields>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>1776</xloc>
      <yloc>640</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] Full load - set key_field_name and key_field_values to NULL</name>
    <type>SetValueConstant</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <usevar>N</usevar>
    <fields>
      <field>
        <name>key_field_name</name>
        <value/>
        <mask/>
        <set_empty_string>N</set_empty_string>
      </field>
      <field>
        <name>key_field_values</name>
        <value/>
        <mask/>
        <set_empty_string>N</set_empty_string>
      </field>
    </fields>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>1776</xloc>
      <yloc>528</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] Insert / update</name>
    <type>InsertUpdate</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <connection>Dummy DB Connection</connection>
    <commit>0</commit>
    <update_bypassed>N</update_bypassed>
    <lookup>
      <schema/>
      <table/>
    </lookup>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>480</xloc>
      <yloc>1088</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] Partial load - add hardcoded constant</name>
    <type>Constant</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <fields>
      <field>
        <name>full_load_flag</name>
        <type>Boolean</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <nullif>FALSE</nullif>
        <length>-1</length>
        <precision>-1</precision>
        <set_empty_string>N</set_empty_string>
      </field>
    </fields>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>1216</xloc>
      <yloc>576</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] S3 file output</name>
    <type>S3FileOutputPlugin</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <separator/>
    <enclosure/>
    <enclosure_forced>N</enclosure_forced>
    <enclosure_fix_disabled>N</enclosure_fix_disabled>
    <header>N</header>
    <footer>N</footer>
    <format>UNIX</format>
    <compression>None</compression>
    <encoding/>
    <endedLine/>
    <fileNameInField>Y</fileNameInField>
    <fileNameField>s3_output_filepath</fileNameField>
    <create_parent_folder>Y</create_parent_folder>
    <file>
      <name>s3n://s3n</name>
      <servlet_output>N</servlet_output>
      <do_not_open_new_file_init>Y</do_not_open_new_file_init>
      <extention/>
      <append>N</append>
      <split>N</split>
      <haspartno>N</haspartno>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <SpecifyFormat>N</SpecifyFormat>
      <date_time_format/>
      <add_to_result_filenames>N</add_to_result_filenames>
      <pad>N</pad>
      <fast_dump>N</fast_dump>
      <splitevery>0</splitevery>
    </file>
    <fields>
      <field>
        <name>mdi_output_json</name>
        <type>None</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <nullif/>
        <trim_type>none</trim_type>
        <length>-1</length>
        <precision>-1</precision>
      </field>
    </fields>
    <access_key>Encrypted </access_key>
    <secret_key>Encrypted </secret_key>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>1488</xloc>
      <yloc>1152</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] Select key field rows</name>
    <type>SelectValues</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <fields>
      <select_unspecified>N</select_unspecified>
    </fields>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>1488</xloc>
      <yloc>112</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] Set data_source_dwid field value to parameter data_source_dwid</name>
    <type>SetValueConstant</type>
    <description/>
    <distribute>N</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <usevar>Y</usevar>
    <fields>
      <field>
        <name>data_source_dwid</name>
        <value/>
        <mask/>
        <set_empty_string>N</set_empty_string>
      </field>
    </fields>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>480</xloc>
      <yloc>832</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] Set environment</name>
    <type>SetValueConstant</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <usevar>Y</usevar>
    <fields>
      <field>
        <name>environment</name>
        <value/>
        <mask/>
        <set_empty_string>N</set_empty_string>
      </field>
    </fields>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>1488</xloc>
      <yloc>752</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] Set etl_batch_id</name>
    <type>SetValueConstant</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <usevar>Y</usevar>
    <fields>
      <field>
        <name>etl_batch_id</name>
        <value/>
        <mask/>
        <set_empty_string>N</set_empty_string>
      </field>
    </fields>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>1488</xloc>
      <yloc>832</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] Set etl_batch_id field value to parameter etl_batch_id</name>
    <type>SetValueConstant</type>
    <description/>
    <distribute>N</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <usevar>Y</usevar>
    <fields>
      <field>
        <name>etl_batch_id</name>
        <value/>
        <mask/>
        <set_empty_string>N</set_empty_string>
      </field>
    </fields>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>480</xloc>
      <yloc>512</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] Set key_field_name</name>
    <type>SetValueConstant</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <usevar>N</usevar>
    <fields>
      <field>
        <name>key_field_name</name>
        <value/>
        <mask/>
        <set_empty_string>N</set_empty_string>
      </field>
    </fields>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>1488</xloc>
      <yloc>256</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] Set token_id</name>
    <type>SetValueConstant</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <usevar>Y</usevar>
    <fields>
      <field>
        <name>token_id</name>
        <value/>
        <mask/>
        <set_empty_string>N</set_empty_string>
      </field>
    </fields>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>1488</xloc>
      <yloc>912</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] Table input</name>
    <type>TableInput</type>
    <description/>
    <distribute>N</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <connection>Dummy DB Connection</connection>
    <sql/>
    <limit>0</limit>
    <lookup/>
    <execute_each_row>N</execute_each_row>
    <variables_active>N</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <cached_row_meta_active>N</cached_row_meta_active>
    <row-meta/>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>480</xloc>
      <yloc>112</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] add a blank field for data_source_dwid to valid stream</name>
    <type>Constant</type>
    <description/>
    <distribute>N</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <fields>
      <field>
        <name>data_source_dwid</name>
        <type>Integer</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <nullif/>
        <length>-1</length>
        <precision>-1</precision>
        <set_empty_string>N</set_empty_string>
      </field>
    </fields>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>480</xloc>
      <yloc>704</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>[template_table_to_table_insert_update_json] add a blank field for etl_batch_id to valid stream</name>
    <type>Constant</type>
    <description/>
    <distribute>N</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <fields>
      <field>
        <name>etl_batch_id</name>
        <type>String</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <nullif/>
        <length>-1</length>
        <precision>-1</precision>
        <set_empty_string>N</set_empty_string>
      </field>
    </fields>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>480</xloc>
      <yloc>384</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step_error_handling>
    <error>
      <source_step>[template_table_to_table_insert_update_json] Insert / update</source_step>
      <target_step>[template_table_to_table_insert_update_json]  Specify logging fields (non-sensitive)</target_step>
      <is_enabled>Y</is_enabled>
      <nr_valuename/>
      <descriptions_valuename/>
      <fields_valuename/>
      <codes_valuename/>
      <max_errors/>
      <max_pct_errors/>
      <min_pct_rows/>
    </error>
    <error>
      <source_step>[template_table_to_table_insert_update_json] Set etl_batch_id field value to parameter etl_batch_id</source_step>
      <target_step>[template_table_to_table_insert_update_json]  Abort Table Output</target_step>
      <is_enabled>N</is_enabled>
      <nr_valuename/>
      <descriptions_valuename/>
      <fields_valuename/>
      <codes_valuename/>
      <max_errors/>
      <max_pct_errors/>
      <min_pct_rows/>
    </error>
  </step_error_handling>
  <slave-step-copy-partition-distribution>
  </slave-step-copy-partition-distribution>
  <slave_transformation>N</slave_transformation>
  <attributes/>
</transformation>
